<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>

<link href='https://fonts.loli.net/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; --title-bar-height:20px; }
.mac-os-11 { --title-bar-height:28px; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
thead, tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-fences-adv-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
svg { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li blockquote { margin: 1rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; padding-bottom: 0px !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
  .typora-export-show-outline .typora-export-sidebar { display: none; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
.MathJax_ref { fill: currentcolor; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.reversefootnote { font-family: ui-monospace, sans-serif; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.6; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
.md-expand mark .md-meta { opacity: 0.3 !important; }
mark .md-meta { color: rgb(0, 0, 0); }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}
.md-diagram-panel .messageText { stroke: none !important; }
.md-diagram-panel .start-state { fill: var(--node-fill); }
.md-diagram-panel .edgeLabel rect { opacity: 1 !important; }
.md-fences.md-fences-math { font-size: 1em; }
.md-fences-advanced:not(.md-focus) { padding: 0px; white-space: nowrap; border: 0px; }
.md-fences-advanced:not(.md-focus) { background: inherit; }
.typora-export-show-outline .typora-export-content { max-width: 1440px; margin: auto; display: flex; flex-direction: row; }
.typora-export-sidebar { width: 300px; font-size: 0.8rem; margin-top: 80px; margin-right: 18px; }
.typora-export-show-outline #write { --webkit-flex:2; flex: 2 1 0%; }
.typora-export-sidebar .outline-content { position: fixed; top: 0px; max-height: 100%; overflow: hidden auto; padding-bottom: 30px; padding-top: 60px; width: 300px; }
@media screen and (max-width: 1024px) {
  .typora-export-sidebar, .typora-export-sidebar .outline-content { width: 240px; }
}
@media screen and (max-width: 800px) {
  .typora-export-sidebar { display: none; }
}
.outline-content li, .outline-content ul { margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px; list-style: none; }
.outline-content ul { margin-top: 0px; margin-bottom: 0px; }
.outline-content strong { font-weight: 400; }
.outline-expander { width: 1rem; height: 1.42857rem; position: relative; display: table-cell; vertical-align: middle; cursor: pointer; padding-left: 4px; }
.outline-expander::before { content: ""; position: relative; font-family: Ionicons; display: inline-block; font-size: 8px; vertical-align: middle; }
.outline-item { padding-top: 3px; padding-bottom: 3px; cursor: pointer; }
.outline-expander:hover::before { content: ""; }
.outline-h1 > .outline-item { padding-left: 0px; }
.outline-h2 > .outline-item { padding-left: 1em; }
.outline-h3 > .outline-item { padding-left: 2em; }
.outline-h4 > .outline-item { padding-left: 3em; }
.outline-h5 > .outline-item { padding-left: 4em; }
.outline-h6 > .outline-item { padding-left: 5em; }
.outline-label { cursor: pointer; display: table-cell; vertical-align: middle; text-decoration: none; color: inherit; }
.outline-label:hover { text-decoration: underline; }
.outline-item:hover { border-color: rgb(245, 245, 245); background-color: var(--item-hover-bg-color); }
.outline-item:hover { margin-left: -28px; margin-right: -28px; border-left: 28px solid transparent; border-right: 28px solid transparent; }
.outline-item-single .outline-expander::before, .outline-item-single .outline-expander:hover::before { display: none; }
.outline-item-open > .outline-item > .outline-expander::before { content: ""; }
.outline-children { display: none; }
.info-panel-tab-wrapper { display: none; }
.outline-item-open > .outline-children { display: block; }
.typora-export .outline-item { padding-top: 1px; padding-bottom: 1px; }
.typora-export .outline-item:hover { margin-right: -8px; border-right: 8px solid transparent; }
.typora-export .outline-expander::before { content: "+"; font-family: inherit; top: -1px; }
.typora-export .outline-expander:hover::before, .typora-export .outline-item-open > .outline-item > .outline-expander::before { content: "−"; }
.typora-export-collapse-outline .outline-children { display: none; }
.typora-export-collapse-outline .outline-item-open > .outline-children, .typora-export-no-collapse-outline .outline-children { display: block; }
.typora-export-no-collapse-outline .outline-expander::before { content: "" !important; }
.typora-export-show-outline .outline-item-active > .outline-item .outline-label { font-weight: 700; }
.md-inline-math-container mjx-container { zoom: 0.95; }
mjx-container { break-inside: avoid; }


:root {
    --side-bar-bg-color: #fafafa;
    --control-text-color: #777;
}

@include-when-export url(https://fonts.loli.net/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext);

/* open-sans-regular - latin-ext_latin */
  /* open-sans-italic - latin-ext_latin */
    /* open-sans-700 - latin-ext_latin */
    /* open-sans-700italic - latin-ext_latin */
  html {
    font-size: 16px;
    -webkit-font-smoothing: antialiased;
}

body {
    font-family: "Open Sans","Clear Sans", "Helvetica Neue", Helvetica, Arial, 'Segoe UI Emoji', sans-serif;
    color: rgb(51, 51, 51);
    line-height: 1.6;
}

#write {
    max-width: 860px;
  	margin: 0 auto;
  	padding: 30px;
    padding-bottom: 100px;
}

@media only screen and (min-width: 1400px) {
	#write {
		max-width: 1024px;
	}
}

@media only screen and (min-width: 1800px) {
	#write {
		max-width: 1200px;
	}
}

#write > ul:first-child,
#write > ol:first-child{
    margin-top: 30px;
}

a {
    color: #4183C4;
}
h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 1rem;
    font-weight: bold;
    line-height: 1.4;
    cursor: text;
}
h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}
h1 tt,
h1 code {
    font-size: inherit;
}
h2 tt,
h2 code {
    font-size: inherit;
}
h3 tt,
h3 code {
    font-size: inherit;
}
h4 tt,
h4 code {
    font-size: inherit;
}
h5 tt,
h5 code {
    font-size: inherit;
}
h6 tt,
h6 code {
    font-size: inherit;
}
h1 {
    font-size: 2.25em;
    line-height: 1.2;
    border-bottom: 1px solid #eee;
}
h2 {
    font-size: 1.75em;
    line-height: 1.225;
    border-bottom: 1px solid #eee;
}

/*@media print {
    .typora-export h1,
    .typora-export h2 {
        border-bottom: none;
        padding-bottom: initial;
    }

    .typora-export h1::after,
    .typora-export h2::after {
        content: "";
        display: block;
        height: 100px;
        margin-top: -96px;
        border-top: 1px solid #eee;
    }
}*/

h3 {
    font-size: 1.5em;
    line-height: 1.43;
}
h4 {
    font-size: 1.25em;
}
h5 {
    font-size: 1em;
}
h6 {
   font-size: 1em;
    color: #777;
}
p,
blockquote,
ul,
ol,
dl,
table{
    margin: 0.8em 0;
}
li>ol,
li>ul {
    margin: 0 0;
}
hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

li p.first {
    display: inline-block;
}
ul,
ol {
    padding-left: 30px;
}
ul:first-child,
ol:first-child {
    margin-top: 0;
}
ul:last-child,
ol:last-child {
    margin-bottom: 0;
}
blockquote {
    border-left: 4px solid #dfe2e5;
    padding: 0 15px;
    color: #777777;
}
blockquote blockquote {
    padding-right: 0;
}
table {
    padding: 0;
    word-break: initial;
}
table tr {
    border: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}
table tr:nth-child(2n),
thead {
    background-color: #f8f8f8;
}
table th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    margin: 0;
    padding: 6px 13px;
}
table td {
    border: 1px solid #dfe2e5;
    margin: 0;
    padding: 6px 13px;
}
table th:first-child,
table td:first-child {
    margin-top: 0;
}
table th:last-child,
table td:last-child {
    margin-bottom: 0;
}

.CodeMirror-lines {
    padding-left: 4px;
}

.code-tooltip {
    box-shadow: 0 1px 1px 0 rgba(0,28,36,.3);
    border-top: 1px solid #eef2f2;
}

.md-fences,
code,
tt {
    border: 1px solid #e7eaed;
    background-color: #f8f8f8;
    border-radius: 3px;
    padding: 0;
    padding: 2px 4px 0px 4px;
    font-size: 0.9em;
}

code {
    background-color: #f3f4f4;
    padding: 0 2px 0 2px;
}

.md-fences {
    margin-bottom: 15px;
    margin-top: 15px;
    padding-top: 8px;
    padding-bottom: 6px;
}


.md-task-list-item > input {
  margin-left: -1.3em;
}

@media print {
    html {
        font-size: 13px;
    }
    pre {
        page-break-inside: avoid;
        word-wrap: break-word;
    }
}

.md-fences {
	background-color: #f8f8f8;
}
#write pre.md-meta-block {
	padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block>.code-tooltip {
	bottom: .375rem;
}

.md-mathjax-midline {
    background: #fafafa;
}

#write>h3.md-focus:before{
	left: -1.5625rem;
	top: .375rem;
}
#write>h4.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h5.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h6.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
.md-image>.md-meta {
    /*border: 1px solid #ddd;*/
    border-radius: 3px;
    padding: 2px 0px 0px 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag {
    color: #a7a7a7;
    opacity: 1;
}

.md-toc { 
    margin-top:20px;
    padding-bottom:20px;
}

.sidebar-tabs {
    border-bottom: none;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

/** focus mode */
.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

header, .context-menu, .megamenu-content, footer{
    font-family: "Segoe UI", "Arial", sans-serif;
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state{
    visibility: visible;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #fafafa;
    background-color: var(--side-bar-bg-color);
}

.md-lang {
    color: #b4654d;
}

/*.html-for-mac {
    --item-hover-bg-color: #E6F0FE;
}*/

#md-notification .btn {
    border: 0;
}

.dropdown-menu .divider {
    border-color: #e5e5e5;
    opacity: 0.4;
}

.ty-preferences .window-content {
    background-color: #fafafa;
}

.ty-preferences .nav-group-item.active {
    color: white;
    background: #999;
}

.menu-item-container a.menu-style-btn {
    background-color: #f5f8fa;
    background-image: linear-gradient( 180deg , hsla(0, 0%, 100%, 0.8), hsla(0, 0%, 100%, 0)); 
}



</style><title>CCL2022 自然语言处理国际前沿动态综述——开放域对话生成前言综述</title>
</head>
<body class='typora-export os-windows'><div class='typora-export-content'>
<div id='write'  class=''><center><b><font size="5">开放域对话生成前言综述</font></b></center><p align="right">——CCL 2022 自然语言处理国际前沿动态综述</p><p>&nbsp;</p><div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n5"><a class="md-toc-inner" href="#总体概览">总体概览</a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n8"><a class="md-toc-inner" href="#1-基础任务">1 基础任务</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n10"><a class="md-toc-inner" href="#11-对话多样性代表工作">1.1 对话多样性代表工作</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n46"><a class="md-toc-inner" href="#12-对话安全性的代表性工作">1.2 对话安全性的代表性工作</a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n82"><a class="md-toc-inner" href="#2-知识融入">2 知识融入</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n84"><a class="md-toc-inner" href="#21-基于常识知识对话的代表性工作">2.1 基于常识知识对话的代表性工作</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n108"><a class="md-toc-inner" href="#22-情感对话代表性工作">2.2 情感对话代表性工作</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n186"><a class="md-toc-inner" href="#23-多模态对话代表性工作">2.3 多模态对话代表性工作</a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n240"><a class="md-toc-inner" href="#3-任务迁移">3 任务迁移</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n242"><a class="md-toc-inner" href="#31-辩论生成代表性工作">3.1 辩论生成代表性工作</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n258"><a class="md-toc-inner" href="#32-对话式推荐代表性工作">3.2 对话式推荐代表性工作</a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n300"><a class="md-toc-inner" href="#总结">总结</a></span></p></div><h1 id='总体概览'><span>总体概览</span></h1><center><img src="https://img-blog.csdnimg.cn/00e9cc4d67d649d18892be80f9053a90.png" width="80%"></center><p>&nbsp;</p><h1 id='1-基础任务'><span>1 基础任务</span></h1><p>&nbsp;</p><h2 id='11-对话多样性代表工作'><span>1.1 对话多样性代表工作</span></h2><p>&emsp;&emsp;<span>多样性这块的工作今年来大多都是基于大模型的，使用比较多且比较有效的一个方法就是用 VAE 的方法.</span></p><p><span>论文标题：</span><a href='https://openreview.net/forum?id=WuVA5LBX5zf'><span>DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation</span></a>
<span>论文网址：</span><a href='https://openreview.net/forum?id=WuVA5LBX5zf'><span>https://openreview.net/forum?id=WuVA5LBX5zf</span></a>
<span>收  录  于：ACL 2022</span></p><center><img src="https://img-blog.csdnimg.cn/b06fd565e9ae4ead96f555988c0d5235.png"></center><p><strong><font size=4><span>方法：</span></font></strong></p><ul><li><p><span>将连续隐变量引入到 encoder-decoder 框架。</span></p></li><li><p><span>encoder 决定隐空间的分布。</span></p></li><li><p><span>隐变量则从隐空间中抽样得到。</span></p></li><li><p><span>encoder 和隐变量共同引导 decoder。</span></p></li><li><p><span>设置 4 个预训练任务：</span></p><ul><li><strong><span>MLM：</span></strong><span>增强 encoder 对上下文的理解；</span></li><li><strong><span>回复生成：</span></strong><span>提高 decoder 的规划能力；</span></li><li><strong><span>KL 散度：</span></strong><span>最小化隐变量的后验分布和先验分布之间的差异；</span></li><li><strong><span>词袋预测：</span></strong><span>减少后验分布崩溃。</span></li></ul></li></ul><p>&emsp;&emsp;<span>这个模型整体的框架还是使用 encoder-decoder 的结构，其中引入了隐变量，这个隐变量就是从 VAE 结构上的一个扩展。主要是包含了 4 个任务，其中一个比较重要的任务是 MLM (Masked Language Model) 任务，它主要是对话的编码，另外一个比较重要的任务就是回复生成，这两个任务定下来之后，剩下的就是我们中间怎么样在编码端和解码端进行先验和后验的对齐，这里就是使用 KL 散度 和 词袋预测 来保证编码和解码的有效性。</span></p><p><strong><font size=4><span>实验结果及结论：</span></font></strong></p><ul><li><span>模型在多个开放域对话集中实现了较好的性能</span></li><li><span>在回复生成方面具有更好的相关性和多样性</span></li></ul><center><img src="https://img-blog.csdnimg.cn/2d9bab40a63245d2a2faa478dbc41d98.png"></center><p>&emsp;&emsp;<em><span>Tabel 2</span></em><span> 中 BLEU-1 和 BLEU-2 评价的是相关性，Distinct-1 和 Distinct-2 评价的是多样性，无论是相关性和多样性，该模型都达到了 SOTA 的效果。</span></p><hr><p>&nbsp;</p><h2 id='12-对话安全性的代表性工作'><span>1.2 对话安全性的代表性工作</span></h2><p><span>论文标题：</span><a href='https://aclanthology.org/2022.acl-long.447/'><span>SaFeRDialogues: Taking Feedback Gracefully after Conversational Safety Failures</span></a>
<span>论文网址：</span><a href='https://aclanthology.org/2022.acl-long.447/'><span>https://aclanthology.org/2022.acl-long.447/</span></a>
<span>收  录  于：ACL 2022</span></p><center><img src="https://img-blog.csdnimg.cn/e56d7bb5ec974a81aa93b3a13c68f5d2.png"></center><p><strong><font size=4><span>动机：</span></font></strong></p><ul><li><p><span>目前开放域对话系统在回复时会生成 </span><strong><span>攻击性的语句</span></strong><span>，与其交互的人类往往能针对这类语句能给出反馈信号 (模型生成的回复存在的问题)。</span></p></li><li><p><span>对于一个负面的反馈信号，现有的 SOTA 模型往往会进一步强化生成的观点 (攻击)，或者 </span><strong><span>忽略</span></strong><span> 用户负面的反馈信息。</span></p><ul><li><span>需要引导对话系统对用户反馈进行合理的反应。</span></li></ul></li></ul><p><strong><font size=4><span>方法：</span></font></strong></p><ul><li><p><span>提出风险对话场景下的针对用户反馈信息进行礼貌回复的数据集 SD</span></p><ul><li><span>风险场景来源于 Bot-Adversarial Dialogure (BAD) 数据，诱导对话模型产生不安全回复；</span></li><li><span>针对负面的反馈 </span><strong><span>修正回复</span></strong><span> 来促进对话的进行。</span></li></ul></li><li><p><span>微调模型</span></p><ul><li><span>结合 Blended Skill Talk 数据保证模型的对话能力；</span></li><li><span>BST2.7 和 DialoGPT 来进行不安全回复的修正，也就是改写和重写的过程。</span></li></ul></li></ul><p><strong><font size=4><span>实验结果及结论：</span></font></strong></p><ul><li><span>在两个模型的多种指标上均取得了明显的提升。</span></li></ul><center><img src="https://img-blog.csdnimg.cn/19c1ef20667f4d75b43a160ad38eb728.png" width="40%"><img src="https://img-blog.csdnimg.cn/3d3786386e354bf389b067411e8e333c.png" width="50%"></center><p>&emsp;&emsp;<span>其中 </span><em><span>Tabel 4</span></em><span> 为自动指标，</span><em><span>Figure 1</span></em><span> 为人工指标。</span></p><hr><h1 id='2-知识融入'><span>2 知识融入</span></h1><p>&nbsp;</p><h2 id='21-基于常识知识对话的代表性工作'><span>2.1 基于常识知识对话的代表性工作</span></h2><p><span>论文标题：</span><a href='https://aclanthology.org/2022.acl-long.88.pdf'><span>Think Before You Speak: Explicitly Generating Implicit Commonsense Knowledge for Response Generation</span></a>
<span>论文网址：</span><a href='https://aclanthology.org/2022.acl-long.88/'><span>https://aclanthology.org/2022.acl-long.88/</span></a>
<span>收  录  于：ACL 2022</span></p><center><img src="https://img-blog.csdnimg.cn/7c3317161c3d42a3b7d511a8e87aeb2d.png"></center><p><strong><font size=4><span>方法：</span></font></strong></p><ul><li><span>利用简单匹配的方法 </span><strong><span>对齐</span></strong><span> 对话集与常识知识图谱。</span></li><li><span>利用模板将知识图谱三元组 </span><strong><span>改写</span></strong><span> 成自然语言或问答形式。</span></li><li><span>利用构造的数据集 </span><strong><span>训练</span></strong><span> 模型</span></li><li><span>先思考：生成知识（使回复可解释）。</span></li><li><span>再回复：生成对话回复。</span></li></ul><p><strong><font size=4><span>实验结果及结论：</span></font></strong></p><ul><li><span>模型再多个开放域对话数据集中实现了较好的性能。</span></li></ul><center><img src="https://img-blog.csdnimg.cn/eee55e369e164468b05c604da484a722.png"></center><center><img src="https://img-blog.csdnimg.cn/3818f956828f4f1285ad62eca1d1259e.png"></center><hr><h2 id='22-情感对话代表性工作'><span>2.2 情感对话代表性工作</span></h2><p><span>论文标题：</span><a href='https://aclanthology.org/2022.acl-long.25.pdf'><span>MISC: A Mixed Strategy-Aware Model integrating COMET for Emotional Support Conversation</span></a>
<span>论文网址：</span><a href='https://aclanthology.org/2022.acl-long.25/'><span>https://aclanthology.org/2022.acl-long.25/</span></a>
<span>收  录  于：ACL 2022</span></p><center><img src="https://img-blog.csdnimg.cn/a06dbc5f82d640abad9b0b196fba8e28.png"></center><p><strong><font size=4><span>动机：</span></font></strong></p><ul><li><p><span>现有的情感对话用于心理支持有两个局限</span></p><ul><li><span>采用对话级别的情感标签，过于粗糙；</span></li><li><span>大多侧重于在共情回复，而不是减少用户的焦虑。</span></li></ul></li></ul><p><strong><font size=4><span>方法：</span></font></strong></p><ul><li><p><span>提出了一个新的模型 MISC</span></p><ul><li><span>预测出用户的细粒度的情绪状态 (分布)；</span></li><li><span>使用混合策略进行情绪回复 (动作)。</span></li></ul></li><li><p><span>融合 COMET 生成模型的常识知识辅助解码。</span></p></li></ul><p><strong><font size=4><span>实验结果及结论：</span></font></strong></p><ul><li><span>MISC 模型在自动评价指标上优于现有的情感对话方法，展现出细粒度的情感理解和移情能力；</span></li><li><span>人工评价显示 MISC 模型能更准确地选择回复策略，增强模型降低用户焦虑的能力；</span></li><li><span>人工评价显示 MISC 模型的回复包含更多的背景知识。</span></li></ul><center><img src="https://img-blog.csdnimg.cn/3e2eeaa4fe1d43c9a21c7c789c57fd4c.png" width="70%"></center><center><img src="https://img-blog.csdnimg.cn/920ce965786b4ef4b13d6c67c6b4fa99.png" width="50%"></center><hr><p><span>论文标题：CauAIN: Causal Aware Interaction Network for Emotion Recognition in Conversations</span>
<span>论文网址：</span><a href='https://www.ijcai.org/proceedings/2022/628'><span>https://www.ijcai.org/proceedings/2022/628</span></a>
<span>收  录  于：IJCAI 2022</span></p><center><img src="https://img-blog.csdnimg.cn/ad9e9bbada84442795c3953952768e74.png" width="60%"></center><p><strong><font size=4><span>动机：</span></font></strong></p><ul><li><p><span>在现有情感分析研究中，对情感的识别往往仅依据当前句子，而忽略了对话历史中存在的能够帮助识别当前情感的深层线索</span></p><ul><li><span>对话某一方自身的话语中，存在可退里情感的因果联系 (Intra-cause)</span></li><li><span>对话双方的话语中，存在可以帮助推理对方情感的交互因果联系 (Inter-cause)</span></li></ul></li><li><p><span>目前还没有相关的标注有情感线索的数据集，因此论文提出了一种利用常识知识自主寻找线索的方法来确定线索所在句子</span></p></li></ul><center><img src="https://img-blog.csdnimg.cn/4fa7eb55defa492ab88cfbdd1dd576f4.png"></center><p><strong><font size=4><span>方法：</span></font></strong></p><ul><li><p><span>利用 ATOMIC 常识知识语料库，获得对话历史每句的 6 种因果线索</span></p><ul><li><span>3 种来自自身因果线索 (Intra-cause)，xEffect，xReact，xWant</span></li><li><span>3 种来自交互因果线索 (Inter-cause)，oEffect，oReact，oWant</span></li></ul></li><li><p><span>利用因果线索，建模对话历史</span></p><ul><li><span>RoBERTa + GRU 建模对话历史文本</span></li><li><span>利用因果线索，获取对话历史每句与当前句情感的相关程度分数</span></li><li><span>利用相关程度分数加权后的向量进行分类获取情感</span></li></ul></li></ul><p><strong><font size=4><span>实验结果及结论：</span></font></strong></p><ul><li><p><span>不同数据集结果</span></p><ul><li><span>CauAIN 分别在三种情感分类数据集 IEMOCAP、DailyDialog、MELD 中均达到了 SOTA 效果</span></li><li><span>CauAIN 模型中，自身因果关系和交互因果关系均对模型的推理起到了正向作用</span></li></ul></li></ul><center><img src="https://img-blog.csdnimg.cn/6adf5818119144a4be045910cd59d514.png" width="60%"></center><hr><h2 id='23-多模态对话代表性工作'><span>2.3 多模态对话代表性工作</span></h2><p><span>论文标题：</span><a href='https://aclanthology.org/2022.acl-long.204.pdf'><span>Multimodal Dialogue Response Generation</span></a>
<span>论文网址：</span><a href='https://aclanthology.org/2022.acl-long.204/'><span>https://aclanthology.org/2022.acl-long.204/</span></a>
<span>收  录  于：ACL 2022</span></p><center><img src="https://img-blog.csdnimg.cn/37e0719af52f4a37a4c626637e2184b7.png" width="45%"></center><p>&nbsp;</p><p><strong><font size=4><span>动机：</span></font></strong></p><ul><li><p><span>多模态开放域对话的回复生成，目前研究者们基本都是围绕检索任务进行研究，很少涉猎 </span><strong><span>生成任务</span></strong></p><ul><li><span>检索模型会受训练数据集的制约，无法在新场景下获得良好表现</span></li><li><span>多模态对话生成任务除文本生成外，还涉及难度较大的图片生成</span></li></ul></li><li><p><span>多模态对话 </span><strong><span>数据集</span></strong><span> 由于人工构造难度大，真实数据涉及隐私等原因，可用数量很少</span></p></li><li><p><span>图像与文本难以 </span><strong><span>联合表示</span></strong><span> 的问题依然存在，图片会含有大量难以用文本表示的抽象信息</span></p></li></ul><center><img src="https://img-blog.csdnimg.cn/f706f2864841484ebc1306861b4b5495.png" width="20%"></center><center><img src="https://img-blog.csdnimg.cn/da33839d335d4f23b0ba816a1713da7e.png"></center><p><strong><font size=4><span>方法：</span></font></strong></p><ul><li><p><span>虽然文本对话+图片的相关数据集较少，但图片描述+图片的数据集很多</span></p><ul><li><span>对于文本回复生成，采用常规的开放域 </span><strong><span>对话回复</span></strong><span> 生成方法</span></li><li><span>对于图片的生成，采用间接生成的策略，先依据对话文本生成 </span><strong><span>图片描述</span></strong><span>，再根据图片描述文本生成图片</span></li></ul></li><li><p><span>采用基于 Transformer 的端到端模型 (Divter)，分别单独预训练两个子模型</span></p><ul><li><span>Text-to-Text 模型，依据对话文本生成文本回复和图片描述</span></li><li><span>Text-to-Image 模型，依据图片描述生成图片</span></li></ul></li></ul><p><strong><font size=4><span>实验结果及结论：</span></font></strong></p><ul><li><p><span>机器评价</span></p><ul><li><span>文本生成任务采用 PPL、BLEU 和 Rouge 作为评价指标，图片生成任务采用 FID 和 IS 评价图片质量</span></li><li><span>Divter 模型在图片描述生成、文本回复生成和图片生成三个任务上均取得了高于 baseline 的表现</span></li></ul></li></ul><center><img src="https://img-blog.csdnimg.cn/29117c7819f54d3c93ce09ee9211f365.png"></center><ul><li><p><span>人工评价</span></p><ul><li><span>Divter 模型在文本和图片方面都获得了更高的人工评价分数</span></li></ul></li></ul><center><img src="https://img-blog.csdnimg.cn/1d1b8db01fab430dbd433ab880c37d96.png" width="60%"></center><hr><h1 id='3-任务迁移'><span>3 任务迁移</span></h1><p>&nbsp;</p><h2 id='31-辩论生成代表性工作'><span>3.1 辩论生成代表性工作</span></h2><p><span>论文标题：</span><a href='https://aclanthology.org/2021.acl-long.366.pdf'><span>Employing Argumentation Knowledge Graphs for Neural Argument Generation</span></a>
<span>论文网址：</span><a href='https://aclanthology.org/2021.acl-long.366/'><span>https://aclanthology.org/2021.acl-long.366/</span></a>
<span>收  录  于：ACL 2021</span></p><center><img src="https://img-blog.csdnimg.cn/5efe65f23f5e4d52916804887b46dec6.png"></center><p><strong><font size=4><span>方法：</span></font></strong></p><ul><li><span>使用论证相关的知识图谱来控制论证的生成</span></li><li><span>用被编码的论证图和文本一起 fine-tune 预训练生成模型 (GPT-2)</span></li></ul><p><strong><font size=4><span>辩论生成结果评价：</span></font></strong></p><p>&nbsp;</p><center><img src="https://img-blog.csdnimg.cn/17af19ab8d9c415999d38416df2518c9.png" width="50%"></center><center><img src="https://img-blog.csdnimg.cn/8496022088f749b69f8b70c560a0645c.png" width="90%"></center><center><img src="https://img-blog.csdnimg.cn/1ca73818cec142f1a4c82b54965d6bdd.png" width="50%"></center><hr><h2 id='32-对话式推荐代表性工作'><span>3.2 对话式推荐代表性工作</span></h2><p><span>论文标题：User-Centric Conversational Recommendation with Multi-Aspect User Modeling</span>
<span>论文网址：</span><a href='https://dl.acm.org/doi/10.1145/3477495.3532074'><span>https://dl.acm.org/doi/10.1145/3477495.3532074</span></a>
<span>收  录  于：SIGIR 2022</span></p><p>&nbsp;</p><center><img src="https://img-blog.csdnimg.cn/96cea01a9d97408ab42fd1910315d8ab.png" width="60%"></center><center><img src="https://img-blog.csdnimg.cn/99e5acc72ec74863a8e75e832179669a.png"></center><p><strong><font size=4><span>动机：</span></font></strong></p><ul><li><p><span>用户偏好在推荐工作中至关重要</span></p></li><li><p><span>对话式推荐属于推荐的一种，因此用户偏好的建模同样重要</span></p><ul><li><span>对话式推荐的用户偏好如何准确建模和表示？</span></li></ul></li></ul><p><strong><font size=4><span>方法：</span></font></strong></p><ul><li><p><span>用户偏好信息的种类</span></p><ul><li><strong><span>当前对话</span></strong><span>上下文语义及包含的属性</span></li><li><strong><span>历史对话</span></strong><span>上下文语义及包含的属性</span></li><li><span>与当前用户</span><strong><span>相似的用户</span></strong><span>信息</span></li></ul></li><li><p><span>UCCR 模型</span></p><ul><li><span>当前对话学习模块</span></li><li><span>历史对话学习模块</span></li><li><span>相似用户选择模块</span></li></ul></li></ul><p><strong><font size=4><span>实验结果及结论：</span></font></strong></p><ul><li><span>模型在中文与英文数据集、商品推荐和对话生成上都达到了 SOTA 效果</span></li></ul><center><img src="https://img-blog.csdnimg.cn/d761b26e419f4a878cb8896f652390ee.png"></center><center><img src="https://img-blog.csdnimg.cn/b9f3dc3559024e05921a4ff87c25b7a7.png"></center><hr><h1 id='总结'><span>总结</span></h1><ul><li><p><span>基础任务</span></p><ul><li><span>在相关性和多样性方面大模型成为了必备基础</span></li><li><span>可以通过改写策略减少不安全回复的产生，但安全的范畴和评价仍然需要系统性定义</span></li></ul></li><li><p><span>知识融入</span></p><ul><li><span>利用结构化知识提升对话模型性能的关键在于如何选取知识</span></li><li><span>情感信息可以看作是一种认知知识，用于指导情感对话和共情回复</span></li><li><span>大模型提升了多模态知识融合的效果，但如何应用在对话中仍然值得探索</span></li></ul></li><li><p><span>任务迁移</span></p><ul><li><span>辩论作为与对话相关的任务，目前重理解、轻生成的趋势没有改变，论辩挖掘与理解相关成果较少应用于生成中，原因可能由于评价指标的限制</span></li><li><span>对话式推荐的研究更加侧重于推荐系统的角度，对话的作用没有充分发挥</span></li></ul></li></ul></div></div>
</body>
</html>